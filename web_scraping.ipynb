{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping - Extraccion de la data\n",
    "\n",
    "Considerar el punto de que:\n",
    "El web scraping que realizado, se encarga de descargar(link referenciando al archivo parket de la data) los archivos de la pagina web de TCL(Taxis & Limousine Commission), por lo que en realidad podrias decir cumplimos con una premisa del web scraping: la extracción de datos de una fuente externa, pero no realizamos una \"disección\" o \"scraping\"(en realidad referie a raspado-raspar) del documento html para luego procesar la data para construir y reorganizar los datos. En este caso, la data ya se obtiene en formato tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver # pip install selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una carpeta para las descargas si no existe\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "print(download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web driver de Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el WebDriver (asegúrate de tener el driver correspondiente)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")\n",
    "#Directorio predeterminado para descargar los archivos\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,  # Cambiar a tu directorio de descargas\n",
    "    \"download.prompt_for_download\": False,       # Desactivar el cuadro de diálogo de descarga\n",
    "    \"download.directory_upgrade\": True,          # Permitir actualizar la carpeta de descarga\n",
    "    \"safebrowsing.enabled\": True                 # Activar descarga segura\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(executable_path=\"chromedriver_win64\\chromedriver.exe\") #Ruta del chromedriver\n",
    "options.headless = True  # Enable headless mode\n",
    "#options.add_argument(\"--window-size=800,640\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page') # URL pagina de la data\n",
    "\n",
    "# Usar WebDriverWait para esperar hasta que la sección con la clase y el id estén visibles\n",
    "wait = WebDriverWait(driver, 20)\n",
    "faq_section_2023 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2023')))\n",
    "faq_section_2024 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2024')))\n",
    "\n",
    "# Buscar todos los enlaces dentro de la sección con class 'faq-answers' y id 'faq2023'\n",
    "taxi_links_2023 = faq_section_2023.find_elements(By.CSS_SELECTOR, 'a[title=\"Yellow Taxi Trip Records\"], a[title=\"Green Taxi Trip Records\"]')\n",
    "taxi_links_2024 = faq_section_2024.find_elements(By.CSS_SELECTOR, 'a[title=\"Yellow Taxi Trip Records\"], a[title=\"Green Taxi Trip Records\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar cada archivo del año 2023\n",
    "for url in taxi_links_2023:\n",
    "    # Extraer el nombre del archivo de la URL\n",
    "    url = url.get_attribute('href')\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(download_dir, file_name)\n",
    "    # Descargar el archivo\n",
    "    print(f\"Descargando {file_name} ...\")\n",
    "    #response = requests.get(url)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=120)  # Aumentar el timeout a 120 segundos\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error: El archivo {file_name} tardó demasiado en responder.\")\n",
    "        continue  # Salta al siguiente archivo si hay un problema de tiempo de espera\n",
    "    # Verificar si la descarga fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Guardar el archivo en la carpeta de descargas\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Archivo descargado y guardado en: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error al descargar {file_name}: Código de estado {response.status_code}\")\n",
    "        \n",
    "\n",
    "# Descargar cada archivo del año 2024\n",
    "for url in taxi_links_2024:\n",
    "    # Extraer el nombre del archivo de la URL\n",
    "    url = url.get_attribute('href')\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(download_dir, file_name)\n",
    "    # Descargar el archivo\n",
    "    print(f\"Descargando {file_name} ...\")\n",
    "    #response = requests.get(url)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=120)  # Aumentar el timeout a 120 segundos\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error: El archivo {file_name} tardó demasiado en responder.\")\n",
    "        continue  # Salta al siguiente archivo si hay un problema de tiempo de espera\n",
    "    # Verificar si la descarga fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Guardar el archivo en la carpeta de descargas\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Archivo descargado y guardado en: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error al descargar {file_name}: Código de estado {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cierra el driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga de los datos acerca del gasto energetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una carpeta para las descargas si no existe\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\\Fuel_rate\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "print(download_dir)\n",
    "# Configura el WebDriver (asegúrate de tener el driver correspondiente)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")\n",
    "#Directorio predeterminado para descargar los archivos\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,       \n",
    "    \"download.directory_upgrade\": True,          \n",
    "    \"safebrowsing.enabled\": True                 \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(executable_path=\"chromedriver_win64\\chromedriver.exe\") #Ruta del chromedriver\n",
    "options.headless = True  # Enable headless mode\n",
    "#options.add_argument(\"--window-size=800,640\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64#wb-auto-6') # URL pagina de la data\n",
    "\n",
    "try:\n",
    "    wait = WebDriverWait(driver, 40)\n",
    "    \n",
    "    # Paso 1: Encontrar el contenedor que tiene los enlaces a las subpáginas\n",
    "    main_section = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'section#dataset-resources.resources')))\n",
    "    print(\"main_section\",main_section)\n",
    "    # Buscar los enlaces a las subpáginas (donde están los datasets)\n",
    "    links = main_section.find_elements(By.CSS_SELECTOR, 'a.heading.resource-heading')\n",
    "    print(links)\n",
    "    # Limitar la iteración a los primeros 8 enlaces\n",
    "    max_links = 8\n",
    "    link_count = 0  # Contador para los enlaces procesados\n",
    "\n",
    "    # Iterar sobre cada enlace a la subpágina\n",
    "    for link in links:\n",
    "        if link_count >= max_links:  # Rompe el loop si ya se procesaron los primeros 5 enlaces\n",
    "            break\n",
    "\n",
    "        href = link.get_attribute(\"href\")  # Obtener el href de la subpágina\n",
    "        print(f\"Navegando a: {href}\")\n",
    "        driver.get(href)  # Navegar a la subpágina\n",
    "        \n",
    "        # Buscar los enlaces de los archivos en la subpágina\n",
    "        try:\n",
    "            # Esperar a que carguen los elementos en la nueva página\n",
    "            subpage_wait = WebDriverWait(driver, 20)\n",
    "            # Encontrar todos los enlaces a archivos CSV en la nueva página\n",
    "            csv_links = subpage_wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a[href*=\"csv\"]')))\n",
    "            \n",
    "            # Descargar cada archivo CSV encontrado\n",
    "            for csv_link in csv_links:\n",
    "                file_href = csv_link.get_attribute(\"href\")\n",
    "                file_name = file_href.split('/')[-1]  # Obtener el nombre del archivo\n",
    "                file_path = os.path.join(download_dir, file_name)\n",
    "\n",
    "                # Comprobar si el archivo ya existe\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"Descargando archivo: {file_href}\")\n",
    "                    driver.get(file_href)  # Descargar el archivo automáticamente\n",
    "                else:\n",
    "                    print(f\"El archivo {file_name} ya existe. Saltando descarga.\")\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"No se encontraron archivos CSV en la subpágina.\")\n",
    "\n",
    "        # Volver a la página anterior para continuar con los otros enlaces\n",
    "        driver.back()\n",
    "\n",
    "        link_count += 1  # Incrementar el contador después de procesar un enlace\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"No se encontraron los elementos dentro del tiempo de espera.\")\n",
    "    print(driver.page_source)  # Imprime el HTML para inspeccionar qué está cargando\n",
    "\n",
    "finally:\n",
    "    driver.quit()  # Cerrar el WebDriver al finalizar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Pablo\\datasets\\TaxisNY\\descargas\n",
      "Descargando green_tripdata_2023-01.parquet ...\n",
      "Archivo descargado y guardado en: c:\\Pablo\\datasets\\TaxisNY\\descargas\\green_tripdata_2023-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear una carpeta para las descargas si no existe\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "print(download_dir)\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")\n",
    "#options.add_argument(\"--headless\")\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(executable_path=\"chromedriver_win64/chromedriver.exe\")  # Ruta del chromedriver\n",
    "#options.headless = True  # Ejecutar en modo headless\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page')  # URL de la página de datos\n",
    "\n",
    "# Esperar hasta que la sección de enlaces de 2023 esté visible\n",
    "wait = WebDriverWait(driver, 20)\n",
    "faq_section_2023 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2023')))\n",
    "\n",
    "# Encontrar todos los enlaces dentro de la sección\n",
    "taxi_links_2023 = faq_section_2023.find_elements(By.CSS_SELECTOR, 'a[title=\"Green Taxi Trip Records\"]')\n",
    "\n",
    "# Extraer la URL del primer elemento\n",
    "first_link = taxi_links_2023[0].get_attribute('href')\n",
    "\n",
    "# Extraer el nombre del archivo de la URL\n",
    "file_name = first_link.split(\"/\")[-1]\n",
    "file_path = os.path.join(download_dir, file_name)\n",
    "\n",
    "# Descargar el archivo\n",
    "print(f\"Descargando {file_name} ...\")\n",
    "try:\n",
    "    response = requests.get(first_link, timeout=120)  # Aumentar el timeout a 120 segundos\n",
    "except requests.exceptions.Timeout:\n",
    "    print(f\"Error: El archivo {file_name} tardó demasiado en responder.\")\n",
    "    driver.quit()  # Cierra el navegador si hay un problema de tiempo de espera\n",
    "    raise  # Lanza la excepción para que el script falle si es necesario\n",
    "\n",
    "# Verificar si la descarga fue exitosa\n",
    "if response.status_code == 200:\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Archivo descargado y guardado en: {file_path}\")\n",
    "else:\n",
    "    print(f\"Error al descargar {file_name}: Código de estado {response.status_code}\")\n",
    "\n",
    "# Cerrar el navegador al final\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'descargas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Definir el directorio donde se encuentran los archivos\n",
    "directorio = 'descargas/'\n",
    "\n",
    "# Lista para almacenar los fragmentos de los nombres de archivo\n",
    "nombres_archivos = []\n",
    "\n",
    "# Iterar sobre los archivos en el directorio\n",
    "for archivo in os.listdir(directorio):\n",
    "    # Verificar si es un archivo y no una carpeta\n",
    "    if os.path.isfile(os.path.join(directorio, archivo)):\n",
    "        # Aquí extraemos la parte del nombre que te interesa, por ejemplo, el prefijo antes de un guión\n",
    "        # Puedes ajustar la lógica de acuerdo a tu necesidad. Ejemplo para extraer antes de un guión:\n",
    "        fragmento = archivo.split('.')[0]  # Cambiar la lógica según lo necesites\n",
    "        fragmento = fragmento[-2:]\n",
    "        #fragmento = archivo[-3:]\n",
    "        #fragmento = str.\n",
    "        nombres_archivos.append(int(fragmento))\n",
    "\n",
    "print(nombres_archivos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
