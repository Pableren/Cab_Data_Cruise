{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping - Extraccion de la data\n",
    "\n",
    "Considerar el punto de que:\n",
    "El web scraping que realizado, se encarga de descargar(link referenciando al archivo parket de la data) los archivos de la pagina web de TCL(Taxis & Limousine Commission), por lo que en realidad podrias decir cumplimos con una premisa del web scraping: la extracción de datos de una fuente externa, pero no realizamos una \"disección\" o \"scraping\"(en realidad referie a raspado-raspar) del documento html para luego procesar la data para construir y reorganizar los datos. En este caso, la data ya se obtiene en formato tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver # pip install selenium\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una carpeta para las descargas si no existe\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "print(download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web driver de Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el WebDriver (asegúrate de tener el driver correspondiente)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")\n",
    "#Directorio predeterminado para descargar los archivos\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,  # Cambiar a tu directorio de descargas\n",
    "    \"download.prompt_for_download\": False,       # Desactivar el cuadro de diálogo de descarga\n",
    "    \"download.directory_upgrade\": True,          # Permitir actualizar la carpeta de descarga\n",
    "    \"safebrowsing.enabled\": True                 # Activar descarga segura\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(executable_path=\"chromedriver_win64\\chromedriver.exe\") #Ruta del chromedriver\n",
    "options.headless = True  # Enable headless mode\n",
    "#options.add_argument(\"--window-size=800,640\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page') # URL pagina de la data\n",
    "\n",
    "# Usar WebDriverWait para esperar hasta que la sección con la clase y el id estén visibles\n",
    "wait = WebDriverWait(driver, 20)\n",
    "faq_section_2023 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2023')))\n",
    "faq_section_2024 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2024')))\n",
    "\n",
    "# Buscar todos los enlaces dentro de la sección con class 'faq-answers' y id 'faq2023'\n",
    "taxi_links_2023 = faq_section_2023.find_elements(By.CSS_SELECTOR, 'a[title=\"Yellow Taxi Trip Records\"], a[title=\"Green Taxi Trip Records\"]')\n",
    "taxi_links_2024 = faq_section_2024.find_elements(By.CSS_SELECTOR, 'a[title=\"Yellow Taxi Trip Records\"], a[title=\"Green Taxi Trip Records\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar cada archivo del año 2023\n",
    "for url in taxi_links_2023:\n",
    "    # Extraer el nombre del archivo de la URL\n",
    "    url = url.get_attribute('href')\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(download_dir, file_name)\n",
    "    # Descargar el archivo\n",
    "    print(f\"Descargando {file_name} ...\")\n",
    "    #response = requests.get(url)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=120)  # Aumentar el timeout a 120 segundos\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error: El archivo {file_name} tardó demasiado en responder.\")\n",
    "        continue  # Salta al siguiente archivo si hay un problema de tiempo de espera\n",
    "    # Verificar si la descarga fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Guardar el archivo en la carpeta de descargas\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Archivo descargado y guardado en: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error al descargar {file_name}: Código de estado {response.status_code}\")\n",
    "        \n",
    "\n",
    "# Descargar cada archivo del año 2024\n",
    "for url in taxi_links_2024:\n",
    "    # Extraer el nombre del archivo de la URL\n",
    "    url = url.get_attribute('href')\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(download_dir, file_name)\n",
    "    # Descargar el archivo\n",
    "    print(f\"Descargando {file_name} ...\")\n",
    "    #response = requests.get(url)\n",
    "    try:\n",
    "        response = requests.get(url, timeout=120)  # Aumentar el timeout a 120 segundos\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error: El archivo {file_name} tardó demasiado en responder.\")\n",
    "        continue  # Salta al siguiente archivo si hay un problema de tiempo de espera\n",
    "    # Verificar si la descarga fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Guardar el archivo en la carpeta de descargas\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Archivo descargado y guardado en: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error al descargar {file_name}: Código de estado {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cierra el driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descarga de los datos acerca del gasto energetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una carpeta para las descargas si no existe\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\\Fuel_rate\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "print(download_dir)\n",
    "# Configura el WebDriver (asegúrate de tener el driver correspondiente)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")\n",
    "#Directorio predeterminado para descargar los archivos\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,       \n",
    "    \"download.directory_upgrade\": True,          \n",
    "    \"safebrowsing.enabled\": True                 \n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(executable_path=\"chromedriver_win64\\chromedriver.exe\") #Ruta del chromedriver\n",
    "options.headless = True  # Enable headless mode\n",
    "#options.add_argument(\"--window-size=800,640\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64#wb-auto-6') # URL pagina de la data\n",
    "\n",
    "try:\n",
    "    wait = WebDriverWait(driver, 40)\n",
    "    \n",
    "    # Paso 1: Encontrar el contenedor que tiene los enlaces a las subpáginas\n",
    "    main_section = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'section#dataset-resources.resources')))\n",
    "    print(\"main_section\",main_section)\n",
    "    # Buscar los enlaces a las subpáginas (donde están los datasets)\n",
    "    links = main_section.find_elements(By.CSS_SELECTOR, 'a.heading.resource-heading')\n",
    "    print(links)\n",
    "    # Limitar la iteración a los primeros 8 enlaces\n",
    "    max_links = 8\n",
    "    link_count = 0  # Contador para los enlaces procesados\n",
    "\n",
    "    # Iterar sobre cada enlace a la subpágina\n",
    "    for link in links:\n",
    "        if link_count >= max_links:  # Rompe el loop si ya se procesaron los primeros 5 enlaces\n",
    "            break\n",
    "\n",
    "        href = link.get_attribute(\"href\")  # Obtener el href de la subpágina\n",
    "        print(f\"Navegando a: {href}\")\n",
    "        driver.get(href)  # Navegar a la subpágina\n",
    "        \n",
    "        # Buscar los enlaces de los archivos en la subpágina\n",
    "        try:\n",
    "            # Esperar a que carguen los elementos en la nueva página\n",
    "            subpage_wait = WebDriverWait(driver, 20)\n",
    "            # Encontrar todos los enlaces a archivos CSV en la nueva página\n",
    "            csv_links = subpage_wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a[href*=\"csv\"]')))\n",
    "            \n",
    "            # Descargar cada archivo CSV encontrado\n",
    "            for csv_link in csv_links:\n",
    "                file_href = csv_link.get_attribute(\"href\")\n",
    "                file_name = file_href.split('/')[-1]  # Obtener el nombre del archivo\n",
    "                file_path = os.path.join(download_dir, file_name)\n",
    "\n",
    "                # Comprobar si el archivo ya existe\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"Descargando archivo: {file_href}\")\n",
    "                    driver.get(file_href)  # Descargar el archivo automáticamente\n",
    "                else:\n",
    "                    print(f\"El archivo {file_name} ya existe. Saltando descarga.\")\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"No se encontraron archivos CSV en la subpágina.\")\n",
    "\n",
    "        # Volver a la página anterior para continuar con los otros enlaces\n",
    "        driver.back()\n",
    "\n",
    "        link_count += 1  # Incrementar el contador después de procesar un enlace\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"No se encontraron los elementos dentro del tiempo de espera.\")\n",
    "    print(driver.page_source)  # Imprime el HTML para inspeccionar qué está cargando\n",
    "\n",
    "finally:\n",
    "    driver.quit()  # Cerrar el WebDriver al finalizar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga del primer archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Pablo\\datasets\\TaxisNY\\descargas\n",
      "Descargando green_tripdata_2023-01.parquet ...\n",
      "Archivo descargado y guardado en: c:\\Pablo\\datasets\\TaxisNY\\descargas\\green_tripdata_2023-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear una carpeta para las descargas si no existe\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\")\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "print(download_dir)\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")\n",
    "#options.add_argument(\"--headless\")\n",
    "options.add_argument('--headless')  # Activa el modo headless\n",
    "#options.add_argument('--disable-gpu')  # Desactiva la GPU para una ejecución más estable en algunos sistemas\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,\n",
    "    \"download.prompt_for_download\": False,\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "service = Service(executable_path=\"chromedriver_win64/chromedriver.exe\")  # Ruta del chromedriver\n",
    "#options.headless = True  # Ejecutar en modo headless\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.get('https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page')  # URL de la página de datos\n",
    "\n",
    "# Esperar hasta que la sección de enlaces de 2023 esté visible\n",
    "wait = WebDriverWait(driver, 20)\n",
    "faq_section_2023 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2023')))\n",
    "\n",
    "# Encontrar todos los enlaces dentro de la sección\n",
    "taxi_links_2023 = faq_section_2023.find_elements(By.CSS_SELECTOR, 'a[title=\"Green Taxi Trip Records\"]')\n",
    "\n",
    "# Extraer la URL del primer elemento\n",
    "first_link = taxi_links_2023[0].get_attribute('href')\n",
    "\n",
    "# Extraer el nombre del archivo de la URL\n",
    "file_name = first_link.split(\"/\")[-1]\n",
    "file_path = os.path.join(download_dir, file_name)\n",
    "\n",
    "# Descargar el archivo\n",
    "print(f\"Descargando {file_name} ...\")\n",
    "try:\n",
    "    response = requests.get(first_link, timeout=120)  # Aumentar el timeout a 120 segundos\n",
    "except requests.exceptions.Timeout:\n",
    "    print(f\"Error: El archivo {file_name} tardó demasiado en responder.\")\n",
    "    driver.quit()  # Cierra el navegador si hay un problema de tiempo de espera\n",
    "    raise  # Lanza la excepción para que el script falle si es necesario\n",
    "\n",
    "# Verificar si la descarga fue exitosa\n",
    "if response.status_code == 200:\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Archivo descargado y guardado en: {file_path}\")\n",
    "else:\n",
    "    print(f\"Error al descargar {file_name}: Código de estado {response.status_code}\")\n",
    "\n",
    "# Cerrar el navegador al final\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Pablo\\datasets\\TaxisNY\\descargas\n",
      "Previously downloaded months: ['01']\n",
      "Downloading file for month 02 from https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
      "File downloaded and saved to: c:\\Pablo\\datasets\\TaxisNY\\descargas\\green_tripdata_2023-02.parquet\n"
     ]
    }
   ],
   "source": [
    "# Create a folder for downloads if it doesn't exist\n",
    "download_dir = os.path.join(os.getcwd(), \"descargas\")  # Define the download directory\n",
    "if not os.path.exists(download_dir):  # Check if the directory exists\n",
    "    os.makedirs(download_dir)  # Create the directory if it doesn't exist\n",
    "print(download_dir)\n",
    "\n",
    "# List to store the downloaded months (as integers)\n",
    "meses_descargados = []\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for archivo in os.listdir(download_dir):\n",
    "    # Check if the file is not a folder\n",
    "    if os.path.isfile(os.path.join(download_dir, archivo)):\n",
    "        try:\n",
    "            # Extract the month (assuming the format is something like 'archivo_01-2023.csv')\n",
    "            fragmento = archivo.split('.')[0][-2:]  # Get the last two characters before the file extension\n",
    "            meses_descargados.append(fragmento)  # Add the month to the list\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing the file {archivo}: {e}\")\n",
    "\n",
    "print(\"Previously downloaded months:\", meses_descargados)\n",
    "\n",
    "# Selenium WebDriver setup\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=800,640\")  # Set the browser window size\n",
    "options.add_argument('--headless')\n",
    "prefs = {\n",
    "    \"download.default_directory\": download_dir,  # Set the download directory\n",
    "    \"download.prompt_for_download\": False,  # Disable download prompt\n",
    "    \"download.directory_upgrade\": True,  # Allow upgrading the directory for downloads\n",
    "    \"safebrowsing.enabled\": True  # Enable safe browsing\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)  # Add preferences to the WebDriver options\n",
    "service = Service(executable_path=\"chromedriver_win64/chromedriver.exe\")  # Path to chromedriver executable\n",
    "driver = webdriver.Chrome(service=service, options=options)  # Initialize WebDriver\n",
    "driver.get('https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page')  # Open the webpage\n",
    "\n",
    "# Wait until the section with 2023 links is visible\n",
    "wait = WebDriverWait(driver, 20)\n",
    "faq_section_2023 = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.faq-answers#faq2023')))\n",
    "taxi_links_2023 = faq_section_2023.find_elements(By.CSS_SELECTOR, 'a[title=\"Green Taxi Trip Records\"]')\n",
    "\n",
    "# Download files for months that have not been downloaded\n",
    "for mes in meses_descargados:\n",
    "    try:\n",
    "        mes_num = int(mes)  # Convert the month to an integer\n",
    "        mes_siguiente = mes_num + 1  # Calculate the next month\n",
    "        mes_siguiente_str = str(mes_siguiente).zfill(2)  # Format the next month as a 2-digit string\n",
    "        \n",
    "        # Check if the file for the next month already exists\n",
    "        file_name = f\"green_tripdata_2023-{mes_siguiente_str}.parquet\"  # Define the expected file name\n",
    "        file_path = os.path.join(download_dir, file_name)\n",
    "        if os.path.exists(file_path):  # If the file exists, skip the download\n",
    "            print(f\"File for month {mes_siguiente_str} already downloaded, skipping download.\")\n",
    "            continue\n",
    "        \n",
    "        # Only continue if the index is valid\n",
    "        indice = mes_siguiente - 1\n",
    "        if indice < len(taxi_links_2023):  # Ensure the index is within the range of available links\n",
    "            enlace = taxi_links_2023[indice].get_attribute('href')  # Get the download link for the month\n",
    "            print(f\"Downloading file for month {mes_siguiente_str} from {enlace}\")\n",
    "\n",
    "            try:\n",
    "                # Make an HTTP request to download the file\n",
    "                response = requests.get(enlace, timeout=120)  # Set a timeout for the request\n",
    "                if response.status_code == 200:  # Check if the request was successful\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(response.content)  # Write the downloaded content to the file\n",
    "                    print(f\"File downloaded and saved to: {file_path}\")\n",
    "                else:\n",
    "                    print(f\"Error downloading {file_name}: Status code {response.status_code}\")\n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"Error: File {file_name} took too long to respond.\")\n",
    "                driver.quit()  # Quit the WebDriver if there's a timeout\n",
    "                raise  # Re-raise the exception to stop further execution\n",
    "\n",
    "        else:\n",
    "            print(\"No more months to download. Process finished.\")\n",
    "            break  # Exit the loop if there are no more months to download\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing month {mes}: {e}\")  # Catch any other errors during processing\n",
    "\n",
    "# Close the WebDriver when done\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
